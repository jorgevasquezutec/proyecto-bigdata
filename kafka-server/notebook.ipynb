{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from typing import List, Dict, Union\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, recall_score, precision_score\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR: str = \"datasets\"\n",
    "RES_DIR: str = \"results\"\n",
    "IMG_SIZE: int = 224\n",
    "NUM_FRAMES_PER_VIDEO: int = 16\n",
    "targets: Dict[str, int] = {\"1\": 0, \"2\": 0, \"3\": 1, \"4\": 1, \"5\": 2, \"6\": 2, \\\n",
    "    \"7\": 3, \"8\": 3, \"HR_1\": 0, \"HR_2\": 1, \"HR_3\": 2, \"HR_4\": 3}\n",
    "\n",
    "def video2frames(video_path: str, resize: Union[int, int] = (IMG_SIZE, IMG_SIZE)) -> np.array:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames: list = []\n",
    "    is_there_frame: bool = True\n",
    "    num_total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    resampling_rate: int = int(num_total_frames / NUM_FRAMES_PER_VIDEO)\n",
    "    idf: int = 0\n",
    "    while is_there_frame and len(frames) < NUM_FRAMES_PER_VIDEO:\n",
    "        idf += 1\n",
    "        is_there_frame, frame = cap.read()\n",
    "        if frame is None: \n",
    "            return np.array([])\n",
    "        if idf % resampling_rate == 0:\n",
    "            # grayscale\n",
    "            # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            # resize\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frames.append(frame)\n",
    "    assert len(frames)==NUM_FRAMES_PER_VIDEO\n",
    "    return np.array(frames)\n",
    "\n",
    "def load_casia_dataset(subpath: str) -> Union[list, list]:\n",
    "    try:\n",
    "        num_folders: int = 1\n",
    "        dataset_x: list = []\n",
    "        dataset_y: list = []\n",
    "        files = glob.glob(f'{DATA_DIR}/{subpath}/**/*.avi', recursive=True)\n",
    "        for f in files:\n",
    "            frames: np.array = video2frames(f)\n",
    "            if frames.size != 0:\n",
    "                dataset_x = [*dataset_x, *frames]\n",
    "                dataset_x = np.array(dataset_x)\n",
    "                vector_path: List[str] = f.split(\"\\\\\")\n",
    "                tmp = [targets[vector_path[-1][:-4]]]*NUM_FRAMES_PER_VIDEO\n",
    "                dataset_y = [*dataset_y, *tmp]\n",
    "    except LookupError: # IndexError, KeyError\n",
    "        print(\"index from video name not found in map targets\")\n",
    "    return dataset_x, dataset_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index from video name not found in map targets\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = load_casia_dataset(\"train_release\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index from video name not found in map targets\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test = load_casia_dataset(\"test_release\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types: List[str] = set(targets.values())\n",
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_y_train = torch.as_tensor(y_train)\n",
    "tensor_y_test = torch.as_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, list_IDs, labels):\n",
    "        self.list_IDs = list_IDs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        preprocess = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        X = preprocess(Image.fromarray(ID))\n",
    "        y = self.labels[index]\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sum of input lengths does not equal the length of the input dataset!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m data_train: MyDataset \u001b[39m=\u001b[39m MyDataset(x_train, tensor_y_train)\n\u001b[1;32m      4\u001b[0m data_test: MyDataset \u001b[39m=\u001b[39m MyDataset(x_test, tensor_y_test)\n\u001b[0;32m----> 5\u001b[0m data_train, data_val \u001b[39m=\u001b[39m random_split(dataset\u001b[39m=\u001b[39;49mdata_train, lengths\u001b[39m=\u001b[39;49m[\u001b[39mround\u001b[39;49m(len_y_train\u001b[39m*\u001b[39;49m\u001b[39m0.8\u001b[39;49m), \u001b[39mround\u001b[39;49m(len_y_train\u001b[39m*\u001b[39;49m\u001b[39m0.2\u001b[39;49m)])\n",
      "File \u001b[0;32m~/anaconda3/envs/spoofing-kafka/lib/python3.9/site-packages/torch/utils/data/dataset.py:351\u001b[0m, in \u001b[0;36mrandom_split\u001b[0;34m(dataset, lengths, generator)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[39m# Cannot verify that dataset is Sized\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39msum\u001b[39m(lengths) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(dataset):  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mSum of input lengths does not equal the length of the input dataset!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    353\u001b[0m indices \u001b[39m=\u001b[39m randperm(\u001b[39msum\u001b[39m(lengths), generator\u001b[39m=\u001b[39mgenerator)\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m    354\u001b[0m \u001b[39mreturn\u001b[39;00m [Subset(dataset, indices[offset \u001b[39m-\u001b[39m length : offset]) \u001b[39mfor\u001b[39;00m offset, length \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(_accumulate(lengths), lengths)]\n",
      "\u001b[0;31mValueError\u001b[0m: Sum of input lengths does not equal the length of the input dataset!"
     ]
    }
   ],
   "source": [
    "batch_size: int = 32\n",
    "len_y_train: int = len(y_train)\n",
    "data_train: MyDataset = MyDataset(x_train, tensor_y_train)\n",
    "data_test: MyDataset = MyDataset(x_test, tensor_y_test)\n",
    "data_train, data_val = random_split(dataset=data_train, lengths=[round(len_y_train*0.8), round(len_y_train*0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader: DataLoader = DataLoader(dataset=data_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=data_val, batch_size=batch_size, shuffle=False)\n",
    "test_loader: DataLoader = DataLoader(dataset=data_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet101 = torchvision.models.resnet101(pretrained=True)\n",
    "for e in resnet101.parameters():\n",
    "   e.requires_grad = False\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "resnet101.fc = nn.Linear(in_features=2048, out_features=len(types), bias=True)\n",
    "optimizer = optim.SGD(resnet101.parameters(), lr=1e-4, weight_decay=0.005, momentum=0.9)\n",
    "resnet101.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, num_epochs) -> Union[List[float], List[float]]:\n",
    "  # train the model\n",
    "  list_train_loss: List[float] = []\n",
    "  list_val_loss: List[float] = []\n",
    "\n",
    "  beg = time.time()\n",
    "  for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "      # forward \n",
    "      output = model(images)\n",
    "      loss   = loss_fn(output, labels)\n",
    "      # change the params\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      # del images, labels, output\n",
    "    \n",
    "    train_loss: float = loss.item()\n",
    "    list_train_loss.append(train_loss)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for images, labels in val_loader:\n",
    "          correct = 0\n",
    "          total = 0\n",
    "          for images, labels in val_loader:\n",
    "              images = images.to(device)\n",
    "              labels = labels.to(device)\n",
    "              outputs = model(images)\n",
    "              loss = loss_fn(outputs, labels)\n",
    "              _, predicted = torch.max(outputs.data, 1)\n",
    "              total += labels.size(0)\n",
    "              correct += (predicted == labels).sum().item()\n",
    "              del images, labels, outputs\n",
    "\n",
    "        val_loss: float = loss.detach().cpu()\n",
    "        list_val_loss.append(val_loss)\n",
    "        print ('Epoch [{}/{}], Train Loss: {:.4f}, Validation Loss {:.4f},  Accuracy: {:.4f}'\n",
    "              .format(epoch+1, num_epochs, train_loss, val_loss, 100*correct/total))\n",
    "  end = time.time()\n",
    "  print('Finished training trainset in {} seconds'.format(round(end-beg, 2)))\n",
    "\n",
    "  return list_train_loss, list_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, save_name: str = \"\"):\n",
    "    with torch.no_grad():\n",
    "        all_predicted: list = []\n",
    "        all_labels: list = []\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_predicted.extend((predicted).tolist())\n",
    "            all_labels.extend((labels).tolist())\n",
    "        matrix = confusion_matrix(all_labels, all_predicted)\n",
    "        df = pd.DataFrame(matrix, index=types, columns=types)\n",
    "        sns.heatmap(df, annot=True, cbar=None, cmap=\"Greens\")\n",
    "        plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Real\")\n",
    "        if save_name == \"\":\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.savefig(RES_DIR+save_name)\n",
    "        print('Test of the model on the {} test images'.format(len(data_test)))\n",
    "        print('Acurracy: {:.2f} %'.format(100*accuracy_score(all_labels, all_predicted)))\n",
    "        print('F1-score: {:.2f} %'.format(100*f1_score(all_labels, all_predicted, average='macro')))\n",
    "        print('Recall: {:.2f} %'.format(100*recall_score(all_labels, all_predicted, average='macro')))\n",
    "        print('Precision: {:.2f} %'.format(100*precision_score(all_labels, all_predicted, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_resnet101, val_loss_resnet101 = train(resnet101, optimizer, loss_fn, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_resnet101, marker='o', label=\"train loss\")\n",
    "plt.plot(val_loss_resnet101, marker='o', label=\"val loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"num epochs\")\n",
    "plt.title(\"Loss vs num epochs\")\n",
    "plt.legend()\n",
    "plt.savefig(RES_DIR+\"/loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(resnet101, \"/confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR: str = \"models\"\n",
    "torch.save(resnet101.state_dict(), MODEL_DIR+\"/resnet101.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('spoofing-kafka')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89fe010ff49a8ce4dbbb05aeda653bd8f0feaf4119263cdf701540a6ad8e4700"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
